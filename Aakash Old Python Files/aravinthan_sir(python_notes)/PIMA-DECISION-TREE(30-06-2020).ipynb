{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv('pima_indians_diabetes_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['preg_count', 'glucose_concentration', 'diastolic_bp',\n",
       "       'triceps_skin_fold_thickness', 'two_hr_serum_insulin', 'bmi',\n",
       "       'diabetes_pedi', 'age', 'diabetes_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima[['preg_count', 'glucose_concentration', 'diastolic_bp',\n",
    "       'triceps_skin_fold_thickness', 'two_hr_serum_insulin', 'bmi',\n",
    "       'diabetes_pedi', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pima[['diabetes_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696969696969697\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       146\n",
      "           1       0.60      0.52      0.56        85\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.67      0.66      0.66       231\n",
      "weighted avg       0.69      0.70      0.69       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier(criterion = \"entropy\", splitter = \"random\", max_depth = 20,  min_samples_split = 8,min_samples_leaf = 2, max_features = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=20, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=8,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='random')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8138528138528138\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       146\n",
      "           1       0.78      0.69      0.73        85\n",
      "\n",
      "    accuracy                           0.81       231\n",
      "   macro avg       0.80      0.79      0.80       231\n",
      "weighted avg       0.81      0.81      0.81       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(metrics.classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "criterion: This parameter determines how the impurity of a split will be measured. \n",
    "    The default value is “gini” but you can also use “entropy” as a metric for impurity."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "splitter: This is how the decision tree searches the features for a split.\n",
    "    The default value is set to “best”. That is, for each node, the algorithm considers all \n",
    "    the features and chooses the best split. If you decide to set the splitter parameter to “random,” \n",
    "    then a random subset of features will be considered. The split will then be made by the best feature within the random subset. The size of the random subset is determined by the max_features parameter. \n",
    "    This is partly where a Random Forest gets its name."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_depth: This determines the maximum depth of the tree. In our case, we use a depth of two to make our decision tree.\n",
    "    The default value is set to none. This will often result in over-fitted decision trees. The depth parameter is one\n",
    "    of the ways in which we can regularize the tree, \n",
    "    or limit the way it grows to prevent over-fitting."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_samples_split: The minimum number of samples a node must contain to consider splitting.\n",
    "    The default value is two. You can use this parameter to regularize your tree."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_samples_leaf: The minimum number of samples needed to be considered a leaf node. \n",
    "    The default value is set to one. Use this parameter to limit the growth of the tree."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_features: The number of features to consider when looking for the best split. \n",
    "    If this value is not set, the decision tree will consider all features available to make the best split. \n",
    "    Depending on your application, it’s often a good idea to tune this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6570507655116842\n",
      "f1 score:  0.5512820512820512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,f1_score\n",
    "print(\"roc_auc_score: \", roc_auc_score(y_test, y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the ‘roc_auc_score’ and the ‘f1_score.’ The ‘roc_auc_score’ is\n",
    "the area under the receiving operating characteristic curve. It is a measure of how well the \n",
    "binary classification model can distinguish classes. A ‘roc_auc_score’ of 0.5 means the model\n",
    "is unable to distinguish between classes. Values close to 1.0 correspond to a strong separation between classes. The ‘f1_score’ is the harmonic mean of precision and recall.\n",
    "Similar to ‘roc_auc_score’, a perfect ‘f1_score’ is equal to 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/building-classification-models-with-sklearn-6a8fd107f0c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
